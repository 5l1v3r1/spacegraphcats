#
# Snakemake configuration file for running spacegraphcats pipelines.
#
# see script 'run' in this directory for a convenient entry point.
#
# Quickstart: `snakeconf/run snakeconf/dory-test.json searchquick`
#

## pull values in from config file:

# name of catlas
catlas_base = config['catlas_base']

# sequence files to use when building catlas
input_sequences = config['input_sequences']

# k-mer size to use for everything
ksize = config['ksize']

# radius for catlas building
radius = config['radius']

# seeds to use when building minhash databases
searchseeds = config.get('searchseeds', 43)

# size of variable-size minhashes
varnum = config.get('varnum', 50)

# search overhead
overhead = config.get('overhead', 0.0)

# suffix to add to search output
experiment = config.get('experiment', '')
search_out_suffix = ''
if experiment:
    search_out_suffix = '_' + experiment

### build some variables for internal use

catlas_dir = '{}_k{}_r{}'.format(catlas_base, ksize, radius)
search_dir = '{}_k{}_r{}_search_oh{}{}'.format(catlas_base, ksize, radius, int(overhead*100), search_out_suffix)

# internal definitions for convenience:
python=sys.executable  # define as the version of Python running snakemake

###############################################################################
## some utility functions.

def parse_seeds(seeds_str):
    seeds = []
    seeds_str = seeds_str.split(',')
    for seed in seeds_str:
        if '-' in seed:
            (start, end) = seed.split('-')
            for s in range(int(start), int(end) + 1):
                seeds.append(s)
        else:
            seeds.append(int(seed))

    return seeds


###############################################################################

## now, build some variables...
SEEDS=parse_seeds(config['searchseeds'])

### rules!

# build catlas & minhashes needed for search
rule build:
    input:
        expand("{catlas_dir}/catlas.csv", catlas_dir=catlas_dir),

# build cDBG using bcalm
rule bcalm_cdbg:
     input:
        "bcalm.{catlas_base}.k{ksize}.inputlist.txt"
     output:
        "bcalm.{catlas_base}.k{ksize}.unitigs.fa"
     shell:
        "bcalm -in bcalm.{catlas_base}.k{ksize}.inputlist.txt -out bcalm.{catlas_base}.k{wildcards.ksize} -kmer-size {wildcards.ksize} -abundance-min 1 >& {output}.log.txt"

# create list of input files for bcalm
rule bcalm_cdbg_inpfiles:
     input:
        input_sequences
     output:
        "bcalm.{catlas_base}.k{ksize}.inputlist.txt"
     shell:
        "echo {input_sequences:q} > bcalm.{catlas_base}.k{ksize}.inputlist.txt"

# build catlas input from bcalm output by reformatting
rule bcalm_catlas_input:
     input:
        expand("bcalm.{catlas_base}.k{ksize}.unitigs.fa", ksize=ksize, catlas_base=catlas_base)
     output:
        "{catlas_dir}/cdbg.gxt",
        "{catlas_dir}/contigs.fa.gz"
     shell:
        "{python} -m search.bcalm_to_gxt {input} {catlas_dir}/cdbg.gxt {catlas_dir}/contigs.fa.gz"

#print(expand("{catlas_dir}/reads.fq.bgz.labels", catlas_dir=catlas_dir))

rule label_reads:
     input:
        expand("{catlas_dir}/reads.fq.bgz.labels", catlas_dir=catlas_dir)

# label the reads by contig
rule label_reads_action:
     input:
        "{catlas_dir}/reads.fq.bgz"
     output:
        "{catlas_dir}/reads.fq.bgz.labels"
     shell:
        "{python} -m search.label_cdbg {catlas_dir} {input} {output}"


# build catlas!
rule build_catlas:
     input:
        "{catlas_dir}/cdbg.gxt",
        "{catlas_dir}/contigs.fa.gz",
     output:
        "{catlas_dir}/first_doms.txt",
        "{catlas_dir}/catlas.csv"
     shell:
        "{python} -m spacegraphcats.catlas --no_checkpoint {catlas_dir} {radius}"

# index contigs, count node sizes
rule make_contigs_kmer_index:
     input:
        "{catlas_dir}/contigs.fa.gz"
     output:
        "{catlas_dir}/contigs.fa.gz.kmeridx"
     shell:
        "{python} -m search.index_contigs_by_kmer {catlas_dir}"

# build minhash databases
rule minhash_db_scaled:
     input:
        "{catlas_dir}/cdbg.gxt",
        "{catlas_dir}/contigs.fa.gz",
        "{catlas_dir}/first_doms.txt",
     output:
        "{catlas_dir}/minhashes.db.k{ksize}.s1000.abund0.seed{seed}"
     shell:
        "{python} -m search.make_catlas_minhashes -k {wildcards.ksize} --seed={wildcards.seed} --scaled=1000 {catlas_dir}"

# build minhash databases
rule minhash_db_var:
     input:
        "{catlas_dir}/cdbg.gxt",
        "{catlas_dir}/contigs.fa.gz",
        "{catlas_dir}/first_doms.txt",
     output:
        "{catlas_dir}/minhashes.db.k{ksize}.var.seed0"
     shell:
        "{python} -m search.make_catlas_minhashes_var -k {wildcards.ksize} --num={varnum} {catlas_dir}"

### Search rules.

def make_query_base(searchfiles, suffix=''):
    x = []
    for filename in searchfiles:
        x.append("{}{}/{}.contigs.sig".format(search_dir, suffix, os.path.basename(filename)))
        x.append("{}{}/{}.cdbg_ids.txt.gz".format(search_dir, suffix, os.path.basename(filename)))
        x.append("{}{}/{}.frontier.txt.gz".format(search_dir, suffix, os.path.basename(filename)))
    return x

#def make_output_cdbg_ids(searchfiles, suffix=''):
#    x = []
#    for filename in searchfiles:
#        x.append("{}{}/{query_filename}.cdbg_ids.txt.gz".format(search_dir, suffix, os.path.basename(filename)))
#    return x

def make_output_reads(searchfiles, suffix=''):
    x = []
    for filename in searchfiles:
        x.append("{}{}/{}.reads.fq.gz".format(search_dir, suffix, os.path.basename(filename)))
    return x

# do a quick search!
rule searchquick:
    input:
        config['searchquick'],
        expand("{catlas_dir}/first_doms.txt", catlas_dir=catlas_dir),
        expand("{catlas_dir}/catlas.csv", catlas_dir=catlas_dir),
        expand("{catlas_dir}/contigs.fa.gz.kmeridx", catlas_dir=catlas_dir)
    output:
        expand("{search_dir}/results.csv", search_dir=search_dir),
        make_query_base(config['searchquick']),
    shell:
        "{python} -m search.extract_nodes_by_query {catlas_dir} {search_dir} --query {config[searchquick]} -k {ksize} --overhead={overhead}"


# do a full search!
rule search:
    input:
        config['search'],
        expand("{catlas_dir}/first_doms.txt", catlas_dir=catlas_dir),
        expand("{catlas_dir}/catlas.csv", catlas_dir=catlas_dir),
        expand("{catlas_dir}/contigs.fa.gz.kmeridx", catlas_dir=catlas_dir)
    output:
        expand("{search_dir}/results.csv", search_dir=search_dir),
        make_query_base(config['search']),
    shell:
        "{python} -m search.extract_nodes_by_query {catlas_dir} {search_dir} --query {config[search]} -k {ksize} --overhead={overhead}"

ruleorder: search > searchquick

### shadow ratio stuff

rule shadow_ratio:
    input:
        expand("{catlas_dir}.shadow.{maxsize}.fa",
               catlas_dir=catlas_dir,
               maxsize=config.get('shadow_ratio_maxsize', 1000))

rule extract_by_shadow_ratio_rule:
    input:
        expand("{catlas_dir}/first_doms.txt", catlas_dir=catlas_dir),
        expand("{catlas_dir}/catlas.csv", catlas_dir=catlas_dir),
#        expand("{catlas_dir}/minhashes.db.k{ksize}.s1000.abund0.seed43", catlas_dir=catlas_dir, ksize=ksize),
    output:
        "{catlas_dir}.shadow.{shadow_ratio_maxsize}.fa"
    shell:
        "{python} -m search.extract_nodes_by_shadow_ratio --maxsize={wildcards.shadow_ratio_maxsize} {catlas_dir} {output}"


# do a frontier search with scaled minhashes - currently deprecated
rule frontier_search:
    input:
        config['search'],
        expand("{catlas_dir}/first_doms.txt", catlas_dir=catlas_dir),
        expand("{catlas_dir}/catlas.csv", catlas_dir=catlas_dir),
        expand("{catlas_dir}/minhashes.db.k{ksize}.s1000.abund0.seed{seed}", catlas_dir=catlas_dir, seed=SEEDS, ksize=ksize),
    output:
        expand("{search_dir}_frontier/results.csv", search_dir=search_dir),
        make_query_base(config['search'], suffix='_frontier'),
    shell:
        "{python} -m search.extract_nodes_by_frontier_query {catlas_dir} {search_dir}_frontier --query {config[search]} -k {ksize} --overhead={overhead} --seed={searchseeds}"

print(make_output_reads(config['search']))

# extract reads based on a search:
rule extract_reads:
    input:
        make_output_reads(config['search'])

#rule extract_reads_rule:
#    input:
#        make_output_cdbg_ids(config['search']),
#        expand("{catlas_dir}/reads.fq.bgz", catlas_dir=catlas_dir),
#        expand("{catlas_dir}/reads.fq.bgz.labels", catlas_dir=catlas_dir)
#    output:
#        make_output_reads(config['search'])
#    shell:
#        "{python} -m search.extract_reads {catlas_dir}/reads.fq.bgz {catlas_dir}/reads.fq.bgz.labels {search_dir}/{query_filename}.cdbg_ids.txt.gz -o {output}"
